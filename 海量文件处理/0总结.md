# 总结

## 如何从大数据中找出高频词
> 有一个 1GB 大小的文件，文件里每一行是一个词，每个词的大小不超过 16B，内存大小限制是 1MB，要求返回频数最高的 100 个词(Top 100)。

----
### 方法总结
1. 分而治之，进行哈希取余；
       
    首先遍历大文件，对遍历到的每个词 x，执行 hash(x) % 5000 ，将结果为 i 的词存放到文件 ai 中。遍历结束后，我们可以得到 5000 个小文件。每个小文件的大小为 200KB 左右。如果有的小文件大小仍然超过 1MB，则采用同样的方式继续进行分解。


2. 使用 HashMap 统计频数；
      
    统计每个小文件中出现频数最高的 100 个词。最简单的方式是使用 HashMap 来实现。其中 key 为词，value 为该词出现的频率。具体方法是：对于遍历到的词 x，如果在 map 中不存在，则执行 map.put(x, 1) ；
      
3. 求解最大的 TopN 个，用小顶堆；求解最小的 TopN 个，用大顶堆。

   依次遍历每个小文件，构建一个小顶堆，堆大小为 100。如果遍历到的词的出现次数大于堆顶词的出现次数，则用新词替换堆顶的词，然后重新调整为小顶堆，遍历结束后，小顶堆上的词就是出现频数最高的 100 个词。
   
## 如何找出一天内访问百度最多的ip
> 现有海量日志数据保存在一个超大文件中，该文件无法直接读入内存，要求从中提取某天访问百度次数最多的那个 IP。

----
### 方法总结
  把ip记录到一个超大文件中，再进行哈希取余，使用hashmap统计频次，找出次数最多的ip
1. 分而治之，进行哈希取余；
2. 使用 HashMap 统计频数；
3. 求解最大的 TopN 个，用小顶堆；求解最小的 TopN 个，用大顶堆。

## 在大量数据中找到不重复的整数
> 在 2.5 亿个整数中找出不重复的整数。注意：内存不足以容纳这 2.5 亿个整数。

### 方法总结
1. 文件内容按照哈希取余切分为小文件、通过hashmap统计频次找出不重复的整数，再合并每个子集结果
2. 位图法 使用bit表示数字的整数出现的次数，但是需要计算内存是否满足需求

## 如何在大量数据中判断一个数是否存在

> 40亿个不重复的没有排序的int型整数，然后再给定一个整数，如何快速判断这个数是否在这40亿个数字中

### 方法总结

1. 分治法 
   文件哈希切割小文件，hashmap查找不存在的数字，整合小文件结果
2. 位图法
   

## 如何查询最热门的查询串？
>搜索引擎会通过日志文件把用户每次检索使用的所有查询串都记录下来，每个查询串的长度不超过 255 字节。假设目前有 1000w 个记录（这些查询串的重复度比较高，虽然总数是 1000w，但如果除去重复后，则不超过 300w 个）。请统计最热门的 10 个查询串，要求使用的内存不能超过 1G。（一个查询串的重复度越高，说明查询它的用户越多，也就越热门。）

### 总结
1. 分治法
2. hashmap，计算总内存 (255+4) * 300w < 1G 统计频次，使用小顶堆取出topN
3. 前缀树，节点存储出现储量 ，小顶堆计算topN
   
## 如何统计不同电话号码的个数？
> 已知某个文件内包含一些电话号码，每个号码为 8 位数字，统计不同号码的个数。

### 总结
申请一个位图数组，长度为 1 亿，初始化为 0。然后遍历所有电话号码，把号码对应的位图中的位置置为 1。遍历完成后，如果 bit 为 1，则表示这个电话号码在文件中存在，否则不存在。bit 值为 1 的数量即为 不同电话号码的个数。